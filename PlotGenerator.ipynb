{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab0b7f-fa2a-40e7-b4f3-efe069ea775e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def load_csv_data(directory, csv_files):\n",
    "    return np.concatenate([\n",
    "        np.loadtxt(os.path.join(directory, file), delimiter=',')\n",
    "        for file in csv_files\n",
    "    ])\n",
    "\n",
    "def extract_start_number(filename):\n",
    "    match = re.search(r'F(\\d+)_', filename)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "def noise_filter(data, window_size):\n",
    "    return savgol_filter(data, window_size, 2, deriv=0, delta=1.0, axis=-1, mode='interp', cval=0.0)\n",
    "\n",
    "\n",
    "def find_clusters(arr, window_size=500, threshold=0.3):\n",
    "    clusters = []\n",
    "    in_cluster = False\n",
    "    start, end = None, None\n",
    "\n",
    "    for i in range(len(arr) - window_size + 1):\n",
    "        window = arr[i:i + window_size]\n",
    "        non_nan_count = np.sum(~np.isnan(window))\n",
    "        if non_nan_count / window_size > threshold:\n",
    "            if not in_cluster:\n",
    "                start = next(j for j, v in enumerate(window) if not np.isnan(v)) + i\n",
    "                in_cluster = True\n",
    "        else:\n",
    "            if in_cluster:\n",
    "                end = next(j for j, v in enumerate(window[::-1]) if not np.isnan(v))\n",
    "                end = i + window_size - end - 1\n",
    "                clusters.append((start, end))\n",
    "                in_cluster = False\n",
    " \n",
    "    if in_cluster:\n",
    "        clusters.append((start, len(arr) - 1))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def find_largest_cluster(bounds):\n",
    "    if not bounds:\n",
    "        return None\n",
    "    return max(bounds, key=lambda x: x[1] - x[0])\n",
    "\n",
    "\n",
    "def truncate_after_clusters(arr, bounds, min_dist=5000):\n",
    "    if not bounds:\n",
    "        return arr\n",
    "\n",
    "    largest_bound = find_largest_cluster(bounds)\n",
    "    last_element = largest_bound[1]\n",
    "    \n",
    "    for start, end in bounds:\n",
    "        if start <= last_element + min_dist and end > last_element:\n",
    "            last_element = end\n",
    "\n",
    "    arr[last_element + 1:] = np.nan\n",
    "    return arr\n",
    "\n",
    "\n",
    "def find_valid_true(mask, window_size, threshold):\n",
    "    mask = np.asarray(mask, dtype=bool)\n",
    "    true_indices = np.where(mask)[0]\n",
    "    \n",
    "    for idx in true_indices:\n",
    "        end = idx + window_size\n",
    "        if end > len(mask):\n",
    "            break\n",
    "        window = mask[idx:end]\n",
    "        if np.mean(window) > threshold:\n",
    "            return idx\n",
    "    return np.nan \n",
    "    \n",
    "\n",
    "def process_directory(directory, mode):\n",
    "    if not os.path.exists(directory):\n",
    "        return np.nan\n",
    "        \n",
    "    csv_files = sorted(\n",
    "        [file for file in os.listdir(directory) if file.endswith('.csv') and 'area' in file],\n",
    "        key=extract_start_number\n",
    "    )\n",
    "    data = load_csv_data(directory, csv_files)\n",
    "    \n",
    "    if mode == \"hatch\":\n",
    "        data[data <= 8] = np.nan                      # remove noise below 8, can be adjusted\n",
    "        weighted_area = noise_filter(data, 10)        # smooth the data with a window size of 10, can be adjusted\n",
    "        mask = (weighted_area != 0) & ~np.isnan(weighted_area)\n",
    "        \n",
    "    elif mode == \"pupation\":\n",
    "        median_value = np.nanmedian(data)\n",
    "        \n",
    "        if median_value < 100:                        # remove noise below 100, can be adjusted\n",
    "            data[data <= median_value] = np.nan\n",
    "        else:\n",
    "            data[data <= 100] = np.nan\n",
    "          \n",
    "\n",
    "        data = truncate_after_clusters(data, find_clusters(data))\n",
    "        weighted_area = noise_filter(data, 20)        # smooth the data with a window size of 20, can be adjusted\n",
    "        mask = (weighted_area != 0) & ~np.isnan(weighted_area)\n",
    "\n",
    "    elif mode == \"eclosion\":\n",
    "        mean_value = np.nanmean(data)\n",
    "\n",
    "        if mean_value < 500:                          # remove noise below 500, can be adjusted\n",
    "            data[data <= mean_value] = np.nan\n",
    "        else:\n",
    "            data[data <= 500] = np.nan\n",
    "            \n",
    "        weighted_area = noise_filter(data, 45)        # smooth the data with a window size of 45, can be adjusted\n",
    "        mask = (weighted_area != 0) & ~np.isnan(weighted_area)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'hatch' or 'pupation' or 'eclosion'\")\n",
    "\n",
    "    \n",
    "    if np.any(mask):\n",
    "        if mode == \"hatch\":\n",
    "            return np.where(mask)[0][0]\n",
    "        elif mode == \"pupation\":\n",
    "            return np.where(mask)[0][-1]\n",
    "        elif mode == \"eclosion\":\n",
    "            true_first_index = find_valid_true(mask, 1800, 0.2)  # adjust threshold as needed\n",
    "            return true_first_index\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "\n",
    "\n",
    "times = np.empty((96, 4), dtype=object)\n",
    "times[:, 1:] = np.nan                                 # initialize hatch & pupation & eclosion times as nan\n",
    "\n",
    "\n",
    "index = 0\n",
    "for letter in tqdm('ABCDEFGH'):\n",
    "    for number in range(1, 13):\n",
    "        well_name = f\"{letter}{number}\"\n",
    "        hatch_dir = f\"/directory/containing/area/csv/files/{well_name}\"  # directory containing the hatching area csv files of each well\n",
    "        pupation_dir = f\"/directory/containing/area/csv/files/{well_name}\" # directory containing the pupation area csv files of each well\n",
    "        eclosion_dir = f\"/directory/containing/area/csv/files/{well_name}\"  # directory containing the eclosion area csv files of each well\n",
    "\n",
    "        if not os.path.isdir(hatch_dir) or not os.listdir(hatch_dir):\n",
    "            hatch_time = np.nan\n",
    "        else:\n",
    "            hatch_time = process_directory(hatch_dir, \"hatch\")\n",
    "            \n",
    "        if not os.path.isdir(pupation_dir) or not os.listdir(pupation_dir) or np.isnan(hatch_time):\n",
    "            pupation_time = np.nan\n",
    "        else:\n",
    "            pupation_time = process_directory(pupation_dir, \"pupation\")\n",
    "\n",
    "        if not os.path.isdir(eclosion_dir) or not os.listdir(eclosion_dir) or np.isnan(hatch_time):\n",
    "            eclosion_time = np.nan\n",
    "        else:\n",
    "            eclosion_time = process_directory(eclosion_dir, \"eclosion\")\n",
    "            \n",
    "        \n",
    "        times[index] = [well_name, hatch_time, pupation_time, eclosion_time]\n",
    "        print(times[index])\n",
    "        index += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env [~/.conda/envs/test-env/]",
   "language": "python",
   "name": "conda_test-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
