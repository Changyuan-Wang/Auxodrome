{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e072a9b-df0f-41dd-8d94-f1a45ecbf338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well Cropper\n",
    "# generate x-y coordinates of well centers, will be used to crop videos\n",
    "\n",
    "\"\"\" import required libraries \"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "\"\"\" setup custom dataclasses and functions \"\"\"\n",
    "\n",
    "# prints message in console and saves it to logs, if enabled\n",
    "def report(text):\n",
    "    print(text)\n",
    "    log.append(text + '\\n')\n",
    "\n",
    "\n",
    "\"\"\" initial setup \"\"\"\n",
    "\n",
    "WellConfig = [27, 1, 3]  # well identification binarizing thresholds\n",
    "ProConfig = [21, 1.5, 3] # well identification binarizing thresholds\n",
    "Blur_val = 9 # blurring threshold for plate identification\n",
    "\n",
    "fps = 1 # acquisition frame rate (per minute)\n",
    "shorten = True # limit processing to first X frames\n",
    "desired_frames = 360 # process these many seconds\n",
    "skip_frames = False # skip first X frames before processing the video\n",
    "timeskip = 360 # amount of frames to skip\n",
    "\n",
    "harsh = False # onlhy process videos with matching amount of wells found\n",
    "Radius_censor = 0 # shrink identified wells by X pixels\n",
    "PlateDim = [8, 12] # multi-well plate dimensions in terms of wells\n",
    "\n",
    "trouble_image = True # save troubleshooting frames\n",
    "trouble_reading = False # print a message every time you read a frame\n",
    "\n",
    "force_well_radius = True # standardize individual well video size\n",
    "forced_radius = 156\n",
    "\n",
    "write_indiv_videos = True # produce a zoomed-in video for each well\n",
    "full_video = False # save original-sized marked videos\n",
    "create_logs = False # create a .txt log file\n",
    "\n",
    "log = []\n",
    "if create_logs:\n",
    "    log.append('WellConfig: [' + str(WellConfig[0]) + ', ' + str(WellConfig[1]) + ', ' + str(WellConfig[2]) + ']\\n')\n",
    "    log.append('ProConfig: [' + str(ProConfig[0]) + ', ' + str(ProConfig[1]) + ', ' + str(ProConfig[2]) + ']\\n')\n",
    "    log.append('BlurVal: ' + str(Blur_val) + '\\n')\n",
    "    log.append('RadiusCens: ' + str(Radius_censor) + '\\n')\n",
    "    if shorten:\n",
    "        log.append('ProcessDur: ' + str(desired_frames) + ' sec\\n')\n",
    "    else:\n",
    "        log.append('ProcessDur: Full\\n')\n",
    "    log.append('\\n')\n",
    "\n",
    "\"\"\" execute video processing \"\"\"\n",
    "file =  # enter the path to the video file\n",
    "\n",
    "cap = cv2.VideoCapture(file)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "path =  # enter the path to the output directory for images that help with troubleshooting\n",
    "\n",
    "\"\"\" find wells from first frame \"\"\"\n",
    "\n",
    "ret, frametemp = cap.read()\n",
    "framer = cv2.cvtColor(frametemp, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "bin_adaptive_im = cv2.adaptiveThreshold(framer,\n",
    "                                        1,\n",
    "                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                        cv2.THRESH_BINARY,\n",
    "                                        WellConfig[0],\n",
    "                                        WellConfig[1])\n",
    "\n",
    "kernel = np.ones((WellConfig[2], WellConfig[2]), np.uint8)\n",
    "bin_im = bin_adaptive_im\n",
    "bin_im = cv2.morphologyEx(bin_im, cv2.MORPH_CLOSE, kernel)\n",
    "bin_im = cv2.morphologyEx(bin_im, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# make plate image\n",
    "well_im = np.stack([bin_im * 255, bin_im * 255, bin_im * 255], axis = -1)\n",
    "well_im = cv2.medianBlur(well_im, Blur_val)\n",
    "\n",
    "well_im = cv2.cvtColor(well_im, cv2.COLOR_BGR2GRAY)\n",
    "ray_im = well_im.copy()\n",
    "\n",
    "if trouble_image:\n",
    "    cv2.imwrite(os.path.join(path, 'trb_processed.jpg'), well_im)\n",
    "\n",
    "circles = cv2.HoughCircles(well_im,\n",
    "                           method = cv2.HOUGH_GRADIENT,\n",
    "                           dp = 1,\n",
    "                           minDist = 75,\n",
    "                           param1 = 100,\n",
    "                           param2 = 30,\n",
    "                           minRadius = 100,\n",
    "                           maxRadius = 160)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "formWells = circles[0, :]  # formatted Plate coordinate list\n",
    "\n",
    "N_wells = len(formWells) # counts found plates\n",
    "\n",
    "N_expected = PlateDim[0] * PlateDim[1]\n",
    "if N_wells != N_expected:\n",
    "    if harsh:\n",
    "        message = 'ERROR: ' + str(N_wells) + ' wells identified; ' + str(N_expected) + ' expected'\n",
    "        report(message)\n",
    "        cap.release()\n",
    "        sys.exit()\n",
    "    else:\n",
    "        message = 'WARNING: ' + str(N_wells) + ' wells identified'\n",
    "        report(message)\n",
    "\n",
    "if trouble_image:\n",
    "    well_im = cv2.cvtColor(well_im, cv2.COLOR_GRAY2RGB)\n",
    "    for i in circles[0, :]:\n",
    "        cv2.circle(well_im, (i[0], i[1]), i[2], (0, 0, 255), 5)\n",
    "        cv2.circle(well_im, (i[0], i[1]), 2, (255, 0, 0), 25)\n",
    "    \n",
    "    cv2.imwrite(os.path.join(path, 'trb_simple_wells.jpg'), well_im)\n",
    "    ray_im_out = cv2.cvtColor(ray_im, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "\n",
    "\"\"\" name wells \"\"\"\n",
    "wells = formWells\n",
    "\n",
    "if force_well_radius:\n",
    "    for well in wells:\n",
    "        well[2] = forced_radius\n",
    "\n",
    "Xmin = 6000\n",
    "Xmax = 0\n",
    "Ymin = 6000\n",
    "Ymax = 0\n",
    "for well in wells:\n",
    "    Xmin = min(Xmin, well[0])\n",
    "    Xmax = max(Xmax, well[0])\n",
    "    Ymin = min(Ymin, well[1])\n",
    "    Ymax = max(Ymax, well[1])\n",
    "Xstep = (Xmax - Xmin) / PlateDim[1]\n",
    "Ystep = (Ymax - Ymin) / PlateDim[0]\n",
    "\n",
    "namedWells = []\n",
    "for well in wells:\n",
    "    if well[0] == Xmin:\n",
    "        Xc = 1\n",
    "    else:\n",
    "        Xc = int((well[0] - Xmin - 1) // Xstep + 1)\n",
    "    if well[1] == Ymin:\n",
    "        Yc = 1\n",
    "    else:\n",
    "        Yc = int((well[1] - Ymin - 1) // Ystep + 1)\n",
    "        \n",
    "    namedWells.append([[Yc, Xc], well])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd95aa-10e5-402b-9ed5-84a6a00fcd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Test YAML File Generator\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "def generate_yaml_files(output_dir, crop_centers):\n",
    "    base_config = {\n",
    "        \"model_path\": \"\",                       # enter the path to the model, i.e. the best checkpoint file\n",
    "        \"model\": {\n",
    "            \"name\": \"ResidualUNet3D\",\n",
    "            \"in_channels\": 3,                  # 3: if you use RGB images; 1: if you use grayscale images\n",
    "            \"out_channels\": 2,\n",
    "            \"layer_order\": \"gcr\",\n",
    "            \"f_maps\": 64,                      # match the f_maps used in training\n",
    "            \"num_groups\": 8,\n",
    "            \"final_sigmoid\": False\n",
    "        },\n",
    "        \"predictor\": {\n",
    "            \"name\": \"VideoPredictor\"\n",
    "        },\n",
    "        \"loaders\": {\n",
    "            \"dataset\": \"VideoDataset\",\n",
    "            \"batch_size\": 2,\n",
    "            \"num_workers\": 8,\n",
    "            \"test\": {\n",
    "                \"file_paths\": [\"/path/to/video/file\"],   # enter the path to the video file\n",
    "                \"spatial_crop\": 320,\n",
    "                \"frame_crop\": 100,               # number of frames that is processed in one batch\n",
    "                \"frame_range\": [700000, 900000], # range of frames specified for processing\n",
    "                \"global_normalization\": True,\n",
    "                \"transformer\": {\n",
    "                    \"raw\": [\n",
    "                        {\"name\": \"Standardize\"},\n",
    "                        {\"name\": \"ToTensor\", \"expand_dims\": True}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for well_data in namedWells:\n",
    "        well_name = chr(well_data[0][0] + 64) + str(well_data[0][1])\n",
    "        crop_center = [int(well_data[1][1]), int(well_data[1][0])]  # [y, x] format\n",
    "        \n",
    "        config = base_config.copy()\n",
    "        config[\"loaders\"][\"output_dir\"] = f\"/path/to/output/directory/{well_name}\" # enter the path to the output directory for predictions\n",
    "        config[\"loaders\"][\"test\"][\"crop_center\"] = crop_center\n",
    "        \n",
    "        yaml_path = os.path.join(output_dir, f\"test_config-VideoTest-{well_name}.yml\")\n",
    "        with open(yaml_path, \"w\") as yaml_file:\n",
    "            yaml.dump(config, yaml_file, default_flow_style=None, sort_keys=False)\n",
    "\n",
    "\n",
    "generate_yaml_files(\"/path/to/save/yaml/files\", namedWells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d292d9-7102-44e0-b4b7-ff631e38599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob Field YAML File Generator\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "def generate_yaml_files(output_dir, crop_centers):\n",
    "    base_config = {\n",
    "        \"model_path\": \"\",                       # enter the path to the model, i.e. the best checkpoint file\n",
    "        \"model\": {\n",
    "            \"name\": \"ResidualUNet3D\",\n",
    "            \"in_channels\": 3,                   # 3: if you use RGB images; 1: if you use grayscale images\n",
    "            \"out_channels\": 2,\n",
    "            \"layer_order\": \"gcr\",\n",
    "            \"f_maps\": 64,                       # match the f_maps used in training\n",
    "            \"num_groups\": 8,\n",
    "            \"final_sigmoid\": False\n",
    "        },\n",
    "        \"predictor\": {\n",
    "            \"name\": \"ProbFieldPredictor\"\n",
    "        },\n",
    "        \"loaders\": {\n",
    "            \"dataset\": \"ProbFieldDataset\",\n",
    "            \"batch_size\": 8,\n",
    "            \"num_workers\": 8,\n",
    "            \"test\": {\n",
    "                \"frame_crop\": 1000,\n",
    "                \"frame_range\": [1, 200001],     # range of frames (in predicted videos of cropped wells) specified for processing\n",
    "                \"threshold\": 250,               # binarization threshold\n",
    "                \"Eclosion\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for well_data in namedWells:\n",
    "        well_name = chr(well_data[0][0] + 64) + str(well_data[0][1])\n",
    "        \n",
    "        config = base_config.copy()\n",
    "        config[\"loaders\"][\"test\"][\"file_paths\"] = [f\"/path/to/predicted/videos/{well_name}/predicted_video_names.avi\"]  # # enter the path to the predicted videos\n",
    "        config[\"loaders\"][\"output_dir\"] = f\"/path/to/output/directory/{well_name}/\"  # enter the path to the output directory\n",
    "        yaml_path = os.path.join(output_dir, f\"test_config-ProbField-{well_name}.yml\")\n",
    "        with open(yaml_path, \"w\") as yaml_file:\n",
    "            yaml.dump(config, yaml_file, default_flow_style=None, sort_keys=False)\n",
    "\n",
    "generate_yaml_files(\"/path/to/save/yaml/files\", namedWells)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env [~/.conda/envs/test-env/]",
   "language": "python",
   "name": "conda_test-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
